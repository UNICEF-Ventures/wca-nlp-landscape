# Manual benchmark entries for Akan (aka)
# This file is NEVER overwritten by populate_research.py.
# Add one-off benchmark results you find in papers here.

evaluations:
  mt:
    - model: facebook/nllb-200-3.3B
      model_url: https://huggingface.co/facebook/nllb-200-3.3B
      results:
        - test_set: FLORES-200 devtest
          source: reported
          source_url: https://arxiv.org/abs/2207.04672
          notes: "Table 39 — multilingual transfer analysis. Only chrF++ on Multilingual MoE."
          metrics:
            - name: chrF++
              value: 36.2
            - name: direction
              value: "eng→aka"
        - test_set: FLORES-200 devtest
          source: reported
          source_url: https://arxiv.org/abs/2207.04672
          notes: "Table 39 — multilingual transfer analysis. Only chrF++ on Multilingual MoE."
          metrics:
            - name: chrF++
              value: 46.7
            - name: direction
              value: "aka→eng"
  llm:
    - model: goldfish-models/aka_latn_full
      model_url: https://huggingface.co/goldfish-models/aka_latn_full
      results:
        - test_set: FLORES-200
          source: reported
          source_url: https://arxiv.org/abs/2408.10441
          notes: "Monolingual LM trained on up to 1GB of aka text. Lower is better."
          metrics:
            - name: Log-perplexity
              value: 132.48
    - model: MaLA-LM/mala-500-10b-v2
      model_url: https://huggingface.co/MaLA-LM/mala-500-10b-v2
      results:
        - test_set: FLORES-200
          source: reported
          source_url: https://arxiv.org/abs/2408.10441
          notes: "Best multilingual baseline from Goldfish Table 5. Lower is better."
          metrics:
            - name: Log-perplexity
              value: 128.37
