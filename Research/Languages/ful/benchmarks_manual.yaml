# Manual benchmark entries for Fulfulde (ful)
# This file is NEVER overwritten by populate_research.py.
# Add one-off benchmark results you find in papers here.

evaluations:
  asr:
    - model: facebook/mms-1b-fl102
      model_url: https://huggingface.co/facebook/mms-1b-fl102
      results:
        - test_set: FLEURS-102 test
          source: reported
          source_url: https://arxiv.org/abs/2305.13516
          notes: "Table A3 — MMS fine-tuned on FLEURS labeled data, FL LM."
          metrics:
            - name: CER
              value: 13.8
        - test_set: FLEURS-102 dev
          source: reported
          source_url: https://arxiv.org/abs/2305.13516
          notes: "Table A3 — MMS fine-tuned on FLEURS labeled data, FL LM."
          metrics:
            - name: CER
              value: 13.9
  llm:
    - model: goldfish-models/fuv_latn_full
      model_url: https://huggingface.co/goldfish-models/fuv_latn_full
      results:
        - test_set: FLORES-200
          source: reported
          source_url: https://arxiv.org/abs/2408.10441
          notes: "Nigerian Fulfulde variety (fuv_Latn). Monolingual LM. Lower is better."
          metrics:
            - name: Log-perplexity
              value: 165.36
