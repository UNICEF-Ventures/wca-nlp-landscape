# Manual benchmark entries for Krio (kri)
# This file is NEVER overwritten by populate_research.py.

# Note: Kreyòl-MT scores are from a Bible-dominated test set. Real-world
# performance on general text is likely significantly lower (the paper reports
# a 68→14.7 BLEU drop for Haitian when switching from Bible to Wikipedia test sets).

evaluations:
  translation:
    - model: jhu-clsp/kreyol-mt
      model_url: https://huggingface.co/jhu-clsp/kreyol-mt
      results:
        - test_set: Kreyòl-MT (bible-based)
          source: reported
          source_url: https://arxiv.org/abs/2405.05376
          metrics:
            - name: BLEU (kri→eng)
              value: 51
            - name: BLEU (eng→kri)
              value: 70
            - name: BLEU (kri→fra)
              value: 58
            - name: BLEU (fra→kri)
              value: 90
