# Manual benchmark entries for Guinea-Bissau Creole (pov)
# This file is NEVER overwritten by populate_research.py.

# Note: Kreyòl-MT scores are from a Bible-dominated test set. Real-world
# performance on general text is likely significantly lower (the paper reports
# a 68→14.7 BLEU drop for Haitian when switching from Bible to Wikipedia test sets).

evaluations:
  translation:
    - model: jhu-clsp/kreyol-mt
      model_url: https://huggingface.co/jhu-clsp/kreyol-mt
      results:
        - test_set: Kreyòl-MT (bible-based)
          source: reported
          source_url: https://arxiv.org/abs/2405.05376
          metrics:
            - name: BLEU (pov→eng)
              value: 42
            - name: BLEU (eng→pov)
              value: 26
